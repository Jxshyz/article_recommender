{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import load_npz\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_name = \"data\"\n",
    "file1 = folder_name + \"\\\\articles.parquet\"\n",
    "file2 = folder_name + \"\\\\train\\\\behaviors.parquet\"\n",
    "file3 = folder_name + \"\\\\train\\\\history.parquet\"\n",
    "file4 = folder_name + \"\\\\validation\\\\behaviors.parquet\"\n",
    "file5 = folder_name + \"\\\\validation\\\\history.parquet\"\n",
    "\n",
    "\n",
    "\n",
    "#   -->      Datasets     <--  #\n",
    "\n",
    "# Articles\n",
    "Articles = pd.read_parquet(file1)\n",
    "\n",
    "# Test set\n",
    "Bhv_test = pd.read_parquet(file2)\n",
    "Hstr_test = pd.read_parquet(file3)\n",
    "\n",
    "# Validation set\n",
    "Bhv_val = pd.read_parquet(file4)\n",
    "Hstr_val = pd.read_parquet(file5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Bhv_test Stats ===\n",
      "\n",
      "Scroll Percentage Stats:\n",
      "count    69098.000000\n",
      "mean        99.566208\n",
      "std          4.944662\n",
      "min          7.000000\n",
      "25%        100.000000\n",
      "50%        100.000000\n",
      "75%        100.000000\n",
      "max        100.000000\n",
      "Name: scroll_percentage, dtype: float64\n",
      "NaN in scroll_percentage: 163789\n",
      "\n",
      "Read Time Stats:\n",
      "count    232887.000000\n",
      "mean         43.901806\n",
      "std          90.299965\n",
      "min           0.000000\n",
      "25%          11.000000\n",
      "50%          21.000000\n",
      "75%          45.000000\n",
      "max        1799.000000\n",
      "Name: read_time, dtype: float64\n",
      "NaN in read_time: 0\n",
      "\n",
      "Rows where article_id matches clicked: 368 / 232887\n",
      "\n",
      "=== Hstr_test Stats ===\n",
      "\n",
      "Exploded Scroll Percentage Stats:\n",
      "count    2.171171e+06\n",
      "mean     6.822356e+01\n",
      "std      3.231243e+01\n",
      "min      0.000000e+00\n",
      "25%      3.500000e+01\n",
      "50%      7.700000e+01\n",
      "75%      1.000000e+02\n",
      "max      1.000000e+02\n",
      "Name: scroll_percentage, dtype: float64\n",
      "NaN in scroll_percentage: 255076\n",
      "\n",
      "Exploded Read Time Stats:\n",
      "count    2.426247e+06\n",
      "mean     6.137053e+01\n",
      "std      1.654371e+02\n",
      "min      0.000000e+00\n",
      "25%      5.000000e+00\n",
      "50%      1.600000e+01\n",
      "75%      5.100000e+01\n",
      "max      1.800000e+03\n",
      "Name: read_time, dtype: float64\n",
      "NaN in read_time: 0\n",
      "\n",
      "=== Bhv_val Stats ===\n",
      "\n",
      "Scroll Percentage Stats:\n",
      "count    70481.000000\n",
      "mean        99.560181\n",
      "std          4.884048\n",
      "min          7.000000\n",
      "25%        100.000000\n",
      "50%        100.000000\n",
      "75%        100.000000\n",
      "max        100.000000\n",
      "Name: scroll_percentage, dtype: float64\n",
      "NaN in scroll_percentage: 174166\n",
      "\n",
      "Read Time Stats:\n",
      "count    244647.000000\n",
      "mean         45.150528\n",
      "std          93.800926\n",
      "min           0.000000\n",
      "25%          11.000000\n",
      "50%          21.000000\n",
      "75%          46.000000\n",
      "max        1799.000000\n",
      "Name: read_time, dtype: float64\n",
      "NaN in read_time: 0\n",
      "\n",
      "Rows where article_id matches clicked: 349 / 244647\n",
      "\n",
      "=== Hstr_val Stats ===\n",
      "\n",
      "Exploded Scroll Percentage Stats:\n",
      "count    1.990657e+06\n",
      "mean     6.819561e+01\n",
      "std      3.240926e+01\n",
      "min      0.000000e+00\n",
      "25%      3.500000e+01\n",
      "50%      7.700000e+01\n",
      "75%      1.000000e+02\n",
      "max      1.000000e+02\n",
      "Name: scroll_percentage, dtype: float64\n",
      "NaN in scroll_percentage: 213516\n",
      "\n",
      "Exploded Read Time Stats:\n",
      "count    2.204173e+06\n",
      "mean     6.142114e+01\n",
      "std      1.648392e+02\n",
      "min      0.000000e+00\n",
      "25%      5.000000e+00\n",
      "50%      1.600000e+01\n",
      "75%      5.200000e+01\n",
      "max      1.800000e+03\n",
      "Name: read_time, dtype: float64\n",
      "NaN in read_time: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def data_exploration(data_folder):\n",
    "    # File paths\n",
    "    file2 = f\"{data_folder}\\\\train\\\\behaviors.parquet\"  # Bhv_test\n",
    "    file3 = f\"{data_folder}\\\\train\\\\history.parquet\"    # Hstr_test\n",
    "    file4 = f\"{data_folder}\\\\validation\\\\behaviors.parquet\"  # Bhv_val\n",
    "    file5 = f\"{data_folder}\\\\validation\\\\history.parquet\"    # Hstr_val\n",
    "\n",
    "    # Load datasets\n",
    "    Bhv_test = pd.read_parquet(file2)\n",
    "    Hstr_test = pd.read_parquet(file3)\n",
    "    Bhv_val = pd.read_parquet(file4)\n",
    "    Hstr_val = pd.read_parquet(file5)\n",
    "\n",
    "    # Helper function for safe evaluation\n",
    "    def safe_eval(x):\n",
    "        try:\n",
    "            return eval(x) if isinstance(x, str) else x\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "    # --- Bhv_test Stats ---\n",
    "    print(\"=== Bhv_test Stats ===\")\n",
    "    print(\"\\nScroll Percentage Stats:\")\n",
    "    print(Bhv_test['scroll_percentage'].describe())\n",
    "    print(f\"NaN in scroll_percentage: {Bhv_test['scroll_percentage'].isna().sum()}\")\n",
    "\n",
    "    print(\"\\nRead Time Stats:\")\n",
    "    print(Bhv_test['read_time'].describe())\n",
    "    print(f\"NaN in read_time: {Bhv_test['read_time'].isna().sum()}\")\n",
    "\n",
    "    Bhv_test['clicked_match'] = Bhv_test.apply(\n",
    "        lambda row: row['article_id'] in safe_eval(row['article_ids_clicked']) if pd.notna(row['article_id']) else False, \n",
    "        axis=1\n",
    "    )\n",
    "    print(f\"\\nRows where article_id matches clicked: {Bhv_test['clicked_match'].sum()} / {len(Bhv_test)}\")\n",
    "\n",
    "    # --- Hstr_test Stats ---\n",
    "    print(\"\\n=== Hstr_test Stats ===\")\n",
    "    Hstr_test['article_ids'] = Hstr_test['article_id_fixed'].apply(safe_eval)\n",
    "    Hstr_test['read_times'] = Hstr_test['read_time_fixed'].apply(safe_eval)\n",
    "    Hstr_test['scroll_percents'] = Hstr_test['scroll_percentage_fixed'].apply(safe_eval)\n",
    "\n",
    "    Hstr_test_exploded = Hstr_test.explode('article_ids')\n",
    "    Hstr_test_exploded['read_time'] = pd.to_numeric(Hstr_test['read_times'].explode(), errors='coerce')\n",
    "    Hstr_test_exploded['scroll_percentage'] = pd.to_numeric(Hstr_test['scroll_percents'].explode(), errors='coerce')\n",
    "\n",
    "    print(\"\\nExploded Scroll Percentage Stats:\")\n",
    "    print(Hstr_test_exploded['scroll_percentage'].describe())\n",
    "    print(f\"NaN in scroll_percentage: {Hstr_test_exploded['scroll_percentage'].isna().sum()}\")\n",
    "\n",
    "    print(\"\\nExploded Read Time Stats:\")\n",
    "    print(Hstr_test_exploded['read_time'].describe())\n",
    "    print(f\"NaN in read_time: {Hstr_test_exploded['read_time'].isna().sum()}\")\n",
    "\n",
    "    # --- Bhv_val Stats ---\n",
    "    print(\"\\n=== Bhv_val Stats ===\")\n",
    "    print(\"\\nScroll Percentage Stats:\")\n",
    "    print(Bhv_val['scroll_percentage'].describe())\n",
    "    print(f\"NaN in scroll_percentage: {Bhv_val['scroll_percentage'].isna().sum()}\")\n",
    "\n",
    "    print(\"\\nRead Time Stats:\")\n",
    "    print(Bhv_val['read_time'].describe())\n",
    "    print(f\"NaN in read_time: {Bhv_val['read_time'].isna().sum()}\")\n",
    "\n",
    "    Bhv_val['clicked_match'] = Bhv_val.apply(\n",
    "        lambda row: row['article_id'] in safe_eval(row['article_ids_clicked']) if pd.notna(row['article_id']) else False, \n",
    "        axis=1\n",
    "    )\n",
    "    print(f\"\\nRows where article_id matches clicked: {Bhv_val['clicked_match'].sum()} / {len(Bhv_val)}\")\n",
    "\n",
    "    # --- Hstr_val Stats ---\n",
    "    print(\"\\n=== Hstr_val Stats ===\")\n",
    "    Hstr_val['article_ids'] = Hstr_val['article_id_fixed'].apply(safe_eval)\n",
    "    Hstr_val['read_times'] = Hstr_val['read_time_fixed'].apply(safe_eval)\n",
    "    Hstr_val['scroll_percents'] = Hstr_val['scroll_percentage_fixed'].apply(safe_eval)\n",
    "\n",
    "    Hstr_val_exploded = Hstr_val.explode('article_ids')\n",
    "    Hstr_val_exploded['read_time'] = pd.to_numeric(Hstr_val['read_times'].explode(), errors='coerce')\n",
    "    Hstr_val_exploded['scroll_percentage'] = pd.to_numeric(Hstr_val['scroll_percents'].explode(), errors='coerce')\n",
    "\n",
    "    print(\"\\nExploded Scroll Percentage Stats:\")\n",
    "    print(Hstr_val_exploded['scroll_percentage'].describe())\n",
    "    print(f\"NaN in scroll_percentage: {Hstr_val_exploded['scroll_percentage'].isna().sum()}\")\n",
    "\n",
    "    print(\"\\nExploded Read Time Stats:\")\n",
    "    print(Hstr_val_exploded['read_time'].describe())\n",
    "    print(f\"NaN in read_time: {Hstr_val_exploded['read_time'].isna().sum()}\")\n",
    "\n",
    "\n",
    "#data_exploration('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total interactions: 4772143\n",
      "Inferred likes: 3032215\n",
      "Users with likes: 18827\n",
      "Articles with likes: 10071\n",
      "Matrix shape: (18827, 12068) (users: 18827, articles: 12068)\n",
      "Number of non-zero entries: 1892965\n",
      "Sparsity: 0.008332\n",
      "Articles liked by user 151570: [np.int64(9778682), np.int64(9777492), np.int64(9778623), np.int64(9778718), np.int64(9773282), np.int64(9779269), np.int64(9779242), np.int64(9779227), np.int64(9774096), np.int64(9772830), np.int64(9772442), np.int64(9779263), np.int64(9780096), np.int64(9773297), np.int64(9776337), np.int64(9777307), np.int64(9778139), np.int64(9778168), np.int64(9773700), np.int64(9773486), np.int64(9773279), np.int64(9773887), np.int64(9774568), np.int64(9774527), np.int64(9773045), np.int64(9772502), np.int64(9772750), np.int64(9776259), np.int64(9775964), np.int64(9772545), np.int64(9772380), np.int64(9772227), np.int64(9772882), np.int64(9772099), np.int64(9774074), np.int64(9772453), np.int64(9772601), np.int64(9772517), np.int64(9773210), np.int64(9770045), np.int64(9775990), np.int64(9776855), np.int64(9777529), np.int64(9773543), np.int64(9773744), np.int64(9774376), np.int64(9776041), np.int64(9771919), np.int64(9772475), np.int64(9773412), np.int64(9773364), np.int64(9771325), np.int64(9779427), np.int64(9774363), np.int64(9774352), np.int64(9773248), np.int64(9774430), np.int64(9774032), np.int64(9774252), np.int64(9771996), np.int64(9772710), np.int64(9772029), np.int64(9779577), np.int64(9780181), np.int64(9772366), np.int64(9772635), np.int64(9773464), np.int64(9776223), np.int64(9776449), np.int64(9778971), np.int64(9775998), np.int64(9776341), np.int64(9769605), np.int64(9776508), np.int64(9776246), np.int64(9776287), np.int64(9775142), np.int64(9759966), np.int64(9772300), np.int64(9771438), np.int64(9776071), np.int64(9777565), np.int64(9779737), np.int64(9779657), np.int64(9773673), np.int64(9773726), np.int64(9773078), np.int64(9774297), np.int64(9778915), np.int64(9772543), np.int64(9775596), np.int64(9778669), np.int64(9771855), np.int64(9771896), np.int64(9776434), np.int64(9772862), np.int64(9773434), np.int64(9776808), np.int64(9773341), np.int64(9770451), np.int64(9770178), np.int64(9770541), np.int64(9769531), np.int64(9772088), np.int64(9777621), np.int64(9770997), np.int64(9767697), np.int64(9777704), np.int64(9772050), np.int64(9772869), np.int64(9775347), np.int64(9774733), np.int64(9775485), np.int64(9774595), np.int64(9779289), np.int64(9765965), np.int64(9779285), np.int64(9773877), np.int64(9771166), np.int64(9773539), np.int64(9773470), np.int64(9773947), np.int64(9772866), np.int64(9773566), np.int64(9770729), np.int64(9771126), np.int64(9775846), np.int64(9775965), np.int64(9768829), np.int64(9765336), np.int64(9770369), np.int64(9772032), np.int64(9777636), np.int64(9777182), np.int64(9760091), np.int64(9769306), np.int64(9776369), np.int64(9672569), np.int64(9771352), np.int64(9772389), np.int64(9780019), np.int64(9778277), np.int64(9779181), np.int64(9773447), np.int64(9777582), np.int64(9772963), np.int64(9772448), np.int64(9772873), np.int64(9772903), np.int64(9771065), np.int64(9773768), np.int64(9777034), np.int64(9779777), np.int64(9769580), np.int64(9771686), np.int64(9768802), np.int64(9775331), np.int64(9774559), np.int64(9771237), np.int64(9767955), np.int64(9777299), np.int64(9776406), np.int64(9778942), np.int64(9776922), np.int64(9765973), np.int64(9779184), np.int64(9779186), np.int64(9771473), np.int64(9773378), np.int64(9772263), np.int64(9770798), np.int64(9760271), np.int64(9779288), np.int64(9775611), np.int64(9774017), np.int64(9773003), np.int64(9771223), np.int64(9769769), np.int64(9740618), np.int64(9773900), np.int64(9767868), np.int64(9769497), np.int64(9769622), np.int64(9630091), np.int64(9773316), np.int64(9754350), np.int64(9778701), np.int64(9770538), np.int64(9770741), np.int64(9770030), np.int64(9770594), np.int64(9767302), np.int64(9762071), np.int64(9752063), np.int64(9767604), np.int64(9763448), np.int64(9770726), np.int64(9773014), np.int64(9771340), np.int64(9769450), np.int64(9748104), np.int64(9769641), np.int64(9770829), np.int64(9770207), np.int64(9767765), np.int64(9773018), np.int64(9754730), np.int64(9764086), np.int64(9776256), np.int64(9739342), np.int64(9769457), np.int64(9729924), np.int64(9766770), np.int64(9757226), np.int64(9769650), np.int64(9741144), np.int64(9759476), np.int64(9766379), np.int64(9748670), np.int64(9744301), np.int64(9746558), np.int64(9750904), np.int64(9741415), np.int64(9749469), np.int64(9766042), np.int64(9667501), np.int64(9773727), np.int64(9770218), np.int64(9750891), np.int64(9770146), np.int64(9762678), np.int64(9744530), np.int64(9765156), np.int64(9766757), np.int64(9766348), np.int64(9761359), np.int64(9773644), np.int64(9754271), np.int64(9745929), np.int64(9751769), np.int64(9761083), np.int64(9770400), np.int64(9766635), np.int64(9746499), np.int64(9738569), np.int64(9738760), np.int64(9739035), np.int64(9739088), np.int64(9739065), np.int64(9738646), np.int64(9739179), np.int64(9739443), np.int64(9728819), np.int64(9739344), np.int64(9738660), np.int64(9740356), np.int64(9740432), np.int64(9740405), np.int64(9741449), np.int64(9741106), np.int64(9741036), np.int64(9738801), np.int64(9741218), np.int64(9738585), np.int64(9741288), np.int64(9741803), np.int64(9742039), np.int64(9742440), np.int64(9738844), np.int64(9742625), np.int64(9741997), np.int64(9742635), np.int64(9742770), np.int64(9735166), np.int64(9743755), np.int64(9743733), np.int64(9730301), np.int64(9743207), np.int64(9739399), np.int64(9742401), np.int64(9743320), np.int64(9744884), np.int64(9744553), np.int64(9744321), np.int64(9744782), np.int64(9745698), np.int64(9745883), np.int64(9747119), np.int64(9746395), np.int64(9747074), np.int64(9747796), np.int64(9746105), np.int64(9747925), np.int64(9745661), np.int64(9745709), np.int64(9747996), np.int64(9748801), np.int64(9748614), np.int64(9748467), np.int64(9748700), np.int64(9748213), np.int64(9750389), np.int64(9749756), np.int64(9750318), np.int64(9750358), np.int64(9749582), np.int64(9745750), np.int64(9750307), np.int64(9747411), np.int64(9749637), np.int64(9727216), np.int64(9749240), np.int64(9751115), np.int64(9751146), np.int64(9751143), np.int64(9751284), np.int64(9751349), np.int64(9751220), np.int64(9749184), np.int64(9749034), np.int64(9751385), np.int64(9751367), np.int64(9751139), np.int64(9751509), np.int64(9751524), np.int64(9750833), np.int64(9751508), np.int64(9751921), np.int64(9751901), np.int64(9749743), np.int64(9751705), np.int64(9751706), np.int64(9751633), np.int64(9749182), np.int64(9752323), np.int64(9750873), np.int64(9749938), np.int64(9749966), np.int64(9752479), np.int64(9752480), np.int64(9752342), np.int64(9753295), np.int64(9752962), np.int64(9752332), np.int64(9753503), np.int64(9752463), np.int64(9754603), np.int64(9753985), np.int64(9754288), np.int64(9754520), np.int64(9754269), np.int64(9753748), np.int64(9755361), np.int64(9755327), np.int64(9753995), np.int64(9755964), np.int64(9756091), np.int64(9754081), np.int64(9756190), np.int64(9756879), np.int64(9756020), np.int64(9756788), np.int64(9758318), np.int64(9758326), np.int64(9758122), np.int64(9757426), np.int64(9757344), np.int64(9758025), np.int64(9758538), np.int64(9758599), np.int64(9758858), np.int64(9759957), np.int64(9759301), np.int64(9759497), np.int64(9760067), np.int64(9760334), np.int64(9760288), np.int64(9761914), np.int64(9761861), np.int64(9761862), np.int64(9761842), np.int64(9762377), np.int64(9760900), np.int64(9761618), np.int64(9762407), np.int64(9757686), np.int64(9761419), np.int64(9763710), np.int64(9763634), np.int64(9763579), np.int64(9763942), np.int64(9763905), np.int64(9763917), np.int64(9763857), np.int64(9764049), np.int64(9761801), np.int64(9764325), np.int64(9758057), np.int64(9763854), np.int64(9765244), np.int64(9765067), np.int64(9765545), np.int64(9765551), np.int64(9765410), np.int64(9765641), np.int64(9766279), np.int64(9765803), np.int64(9766627), np.int64(9766242), np.int64(9766886), np.int64(9762135), np.int64(9769888), np.int64(9769220), np.int64(9768260), np.int64(9738684), np.int64(9738303), np.int64(9739471), np.int64(9740237), np.int64(9739938), np.int64(9740427), np.int64(9740223), np.int64(9740013), np.int64(9744297), np.int64(9745221), np.int64(9745912), np.int64(9746483), np.int64(9746482), np.int64(9738714), np.int64(9751532), np.int64(9751531), np.int64(9744480), np.int64(9751564), np.int64(9747369), np.int64(9757372), np.int64(9757541), np.int64(9757428), np.int64(9755749), np.int64(9759782), np.int64(9762953), np.int64(9764420), np.int64(9764443), np.int64(9767220), np.int64(9769135), np.int64(9739864), np.int64(9741788), np.int64(9746068), np.int64(9746049), np.int64(9751646), np.int64(9758074), np.int64(9763090), np.int64(9741802), np.int64(9741804), np.int64(9741896), np.int64(9741830), np.int64(9742188), np.int64(9744738), np.int64(9745869), np.int64(9748798), np.int64(9750829), np.int64(9749634), np.int64(9752155), np.int64(9752905), np.int64(9753521), np.int64(9753543), np.int64(9753526), np.int64(9755511), np.int64(9758561), np.int64(9766048), np.int64(9739272), np.int64(9751290), np.int64(9755119), np.int64(9739802), np.int64(9740332), np.int64(9741419), np.int64(9741428), np.int64(9741523), np.int64(9741986), np.int64(9742423), np.int64(9742542), np.int64(9742748), np.int64(9743768), np.int64(9744213), np.int64(9748470), np.int64(9750691), np.int64(9750304), np.int64(9751107), np.int64(9751593), np.int64(9751252), np.int64(9752846), np.int64(9754361), np.int64(9756362), np.int64(9756297), np.int64(9754121), np.int64(9759025), np.int64(9759026), np.int64(9759045), np.int64(9762718), np.int64(9763120), np.int64(9763202), np.int64(9763247), np.int64(9763279), np.int64(9762548), np.int64(9764079), np.int64(9764403), np.int64(9765153), np.int64(9767071), np.int64(9768722), np.int64(9768962), np.int64(9743779), np.int64(9740845), np.int64(9744481), np.int64(9746170), np.int64(9745706), np.int64(9747277), np.int64(9755430), np.int64(9758483), np.int64(9759398), np.int64(9744381), np.int64(9748532), np.int64(9758453), np.int64(9765450), np.int64(9739036), np.int64(9735495), np.int64(9741057), np.int64(9740570), np.int64(9741421), np.int64(9741259), np.int64(9742966), np.int64(9744193), np.int64(9745419), np.int64(9744793), np.int64(9745532), np.int64(9746723), np.int64(9745898), np.int64(9746035), np.int64(9745511), np.int64(9745745), np.int64(9744969), np.int64(9748038), np.int64(9747526), np.int64(9748323), np.int64(9745484), np.int64(9749886), np.int64(9750862), np.int64(9748750), np.int64(9755098), np.int64(9761803), np.int64(9761531), np.int64(9768564), np.int64(9750500), np.int64(9741850), np.int64(9747328), np.int64(9751123), np.int64(9763400), np.int64(9740236), np.int64(9740408), np.int64(9744492), np.int64(9744386), np.int64(9745476), np.int64(9746687), np.int64(9750995), np.int64(9751778), np.int64(9753540), np.int64(9747961), np.int64(9753811), np.int64(9756369), np.int64(9760386), np.int64(9766949), np.int64(9744477), np.int64(9745613), np.int64(9747267), np.int64(9760112), np.int64(9763559), np.int64(9767027), np.int64(9740969), np.int64(9742479), np.int64(9742793), np.int64(9748706), np.int64(9750076), np.int64(9752939), np.int64(9754149), np.int64(9754490), np.int64(9756295), np.int64(9754366), np.int64(9729988), np.int64(9740749), np.int64(9742255), np.int64(9743195), np.int64(9744114), np.int64(9745298), np.int64(9744098), np.int64(9747270), np.int64(9750864), np.int64(9751772), np.int64(9753207), np.int64(9765010), np.int64(9765943), np.int64(9738746), np.int64(9740710), np.int64(9737154), np.int64(9740591), np.int64(9742280), np.int64(9744595), np.int64(9745399), np.int64(9744152), np.int64(9751517), np.int64(9751654), np.int64(9763113), np.int64(9742145), np.int64(9746129), np.int64(9755178), np.int64(9761087), np.int64(9738447), np.int64(9739333), np.int64(9751673), np.int64(9764362), np.int64(9759612), np.int64(9740724), np.int64(9747666), np.int64(9733845), np.int64(9743602), np.int64(9753774), np.int64(9755580), np.int64(9757819), np.int64(9736706), np.int64(9755269), np.int64(9758544), np.int64(9766428), np.int64(9761127), np.int64(9736767), np.int64(9739452), np.int64(9740843), np.int64(9746202), np.int64(9740872), np.int64(9752416), np.int64(9744925), np.int64(9742775), np.int64(9751202), np.int64(9754374), np.int64(9761588), np.int64(9764433), np.int64(9746615), np.int64(9746376), np.int64(9762067), np.int64(9746148), np.int64(9746855), np.int64(9751665), np.int64(9754484), np.int64(9763656), np.int64(9763882), np.int64(9739362), np.int64(9742279), np.int64(9754413), np.int64(9751688), np.int64(9759508), np.int64(9760477), np.int64(9750527), np.int64(9746697), np.int64(9758765), np.int64(9761273), np.int64(9751717), np.int64(9753773), np.int64(9739844), np.int64(9740553), np.int64(9761782), np.int64(9746639), np.int64(9760446), np.int64(9735278), np.int64(9760390), np.int64(9751267), np.int64(9754290), np.int64(9765907), np.int64(9750196), np.int64(9742261), np.int64(9763291), np.int64(9763949), np.int64(9492468), np.int64(9663313), np.int64(9744453), np.int64(9725235), np.int64(9749110), np.int64(9782884), np.int64(9788497), np.int64(9783852), np.int64(9779653), np.int64(9780514), np.int64(9784839), np.int64(9784856), np.int64(9783850), np.int64(9783790), np.int64(9777199), np.int64(9781756), np.int64(9783276), np.int64(9780547), np.int64(9780769), np.int64(9785310), np.int64(9784949), np.int64(9785434), np.int64(9789977), np.int64(9784793), np.int64(9789065), np.int64(9788471), np.int64(9781389), np.int64(9781086), np.int64(9786378), np.int64(9784947), np.int64(9783213), np.int64(9785892), np.int64(9787176), np.int64(9785030), np.int64(9782085), np.int64(9786268), np.int64(9787230), np.int64(9777705), np.int64(9790085), np.int64(9789704), np.int64(9789922), np.int64(9788462), np.int64(9786247), np.int64(9787499), np.int64(9788125), np.int64(9783042), np.int64(9781785), np.int64(9787465), np.int64(9783628), np.int64(9790548), np.int64(9785751), np.int64(9785553), np.int64(9784875), np.int64(9784852), np.int64(9782237), np.int64(9788677), np.int64(9788106), np.int64(9789001), np.int64(9790811), np.int64(9790784), np.int64(9788393), np.int64(9776147), np.int64(9790827), np.int64(9786381), np.int64(9788361), np.int64(9788310), np.int64(9788239), np.int64(9785049), np.int64(9789883), np.int64(9782869), np.int64(9781558), np.int64(9790475), np.int64(9790052), np.int64(9790414), np.int64(9785145), np.int64(9785112), np.int64(9785076), np.int64(9789745), np.int64(9789747), np.int64(9786210), np.int64(9789927), np.int64(9789837), np.int64(9781316), np.int64(9783019), np.int64(9786718), np.int64(9786243), np.int64(9789379), np.int64(9786649), np.int64(9782672)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_sparse(data_folder, output_file='user_item_likes_matrix_all.npz'):\n",
    "    # File paths\n",
    "    file1 = f\"{data_folder}\\\\articles.parquet\"\n",
    "    file2 = f\"{data_folder}\\\\train\\\\behaviors.parquet\"  # Test behaviors\n",
    "    file3 = f\"{data_folder}\\\\train\\\\history.parquet\"    # Test history\n",
    "    file4 = f\"{data_folder}\\\\validation\\\\behaviors.parquet\"  # Val behaviors\n",
    "    file5 = f\"{data_folder}\\\\validation\\\\history.parquet\"    # Val history\n",
    "\n",
    "    # Load datasets\n",
    "    Articles = pd.read_parquet(file1)\n",
    "    Bhv_test = pd.read_parquet(file2)  # Changed to Bhv_test\n",
    "    Hstr_test = pd.read_parquet(file3) # Changed to Hstr_test\n",
    "    Bhv_val = pd.read_parquet(file4)\n",
    "    Hstr_val = pd.read_parquet(file5)\n",
    "\n",
    "    # Helper function for safe evaluation\n",
    "    def safe_eval(x):\n",
    "        try:\n",
    "            return eval(x) if isinstance(x, str) else x\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "    # Preprocess Bhv_test\n",
    "    Bhv_test = Bhv_test.dropna(subset=['article_id'])\n",
    "    Bhv_test['article_id'] = Bhv_test['article_id'].astype(int)\n",
    "    merged_test = Bhv_test.merge(Articles[['article_id', 'body', 'article_type']], \n",
    "                                 on='article_id', how='left')\n",
    "\n",
    "    # Preprocess Hstr_test\n",
    "    Hstr_test['article_id_fixed'] = Hstr_test['article_id_fixed'].apply(safe_eval)\n",
    "    Hstr_test['read_time_fixed'] = Hstr_test['read_time_fixed'].apply(safe_eval)\n",
    "    Hstr_test['scroll_percentage_fixed'] = Hstr_test['scroll_percentage_fixed'].apply(safe_eval)\n",
    "    Hstr_test_exploded = Hstr_test.explode('article_id_fixed')\n",
    "    Hstr_test_exploded['read_time'] = pd.to_numeric(Hstr_test['read_time_fixed'].explode(), errors='coerce')\n",
    "    Hstr_test_exploded['scroll_percentage'] = pd.to_numeric(Hstr_test['scroll_percentage_fixed'].explode(), errors='coerce')\n",
    "    Hstr_test_exploded['article_id'] = pd.to_numeric(Hstr_test_exploded['article_id_fixed'], errors='coerce')\n",
    "    Hstr_test_exploded = Hstr_test_exploded.dropna(subset=['article_id'])\n",
    "    Hstr_test_exploded['article_id'] = Hstr_test_exploded['article_id'].astype(int)\n",
    "    Hstr_test_merged = Hstr_test_exploded.merge(Articles[['article_id', 'body', 'article_type']], \n",
    "                                                on='article_id', how='left')\n",
    "\n",
    "    # Preprocess Bhv_val\n",
    "    Bhv_val = Bhv_val.dropna(subset=['article_id'])\n",
    "    Bhv_val['article_id'] = Bhv_val['article_id'].astype(int)\n",
    "    merged_val = Bhv_val.merge(Articles[['article_id', 'body', 'article_type']], \n",
    "                              on='article_id', how='left')\n",
    "\n",
    "    # Preprocess Hstr_val\n",
    "    Hstr_val['article_id_fixed'] = Hstr_val['article_id_fixed'].apply(safe_eval)\n",
    "    Hstr_val['read_time_fixed'] = Hstr_val['read_time_fixed'].apply(safe_eval)\n",
    "    Hstr_val['scroll_percentage_fixed'] = Hstr_val['scroll_percentage_fixed'].apply(safe_eval)\n",
    "    Hstr_val_exploded = Hstr_val.explode('article_id_fixed')\n",
    "    Hstr_val_exploded['read_time'] = pd.to_numeric(Hstr_val['read_time_fixed'].explode(), errors='coerce')\n",
    "    Hstr_val_exploded['scroll_percentage'] = pd.to_numeric(Hstr_val['scroll_percentage_fixed'].explode(), errors='coerce')\n",
    "    Hstr_val_exploded['article_id'] = pd.to_numeric(Hstr_val_exploded['article_id_fixed'], errors='coerce')\n",
    "    Hstr_val_exploded = Hstr_val_exploded.dropna(subset=['article_id'])\n",
    "    Hstr_val_exploded['article_id'] = Hstr_val_exploded['article_id'].astype(int)\n",
    "    Hstr_val_merged = Hstr_val_exploded.merge(Articles[['article_id', 'body', 'article_type']], \n",
    "                                             on='article_id', how='left')\n",
    "\n",
    "    # Combine all data\n",
    "    combined_df = pd.concat([merged_test, Hstr_test_merged, merged_val, Hstr_val_merged], ignore_index=True)\n",
    "    combined_df['body_length'] = combined_df['body'].apply(lambda x: len(str(x)) if pd.notnull(x) else 0)\n",
    "\n",
    "    # Infer \"Likes\"\n",
    "    def is_low_text_article(article_type, body_length):\n",
    "        low_text_types = ['video']\n",
    "        return (article_type in low_text_types) or (body_length < 500)\n",
    "\n",
    "    combined_df['is_low_text'] = combined_df.apply(lambda row: is_low_text_article(row['article_type'], row['body_length']), axis=1)\n",
    "    combined_df['scroll_percentage'] = pd.to_numeric(combined_df['scroll_percentage'], errors='coerce').fillna(0)\n",
    "    combined_df['read_time'] = pd.to_numeric(combined_df['read_time'], errors='coerce').fillna(0)\n",
    "\n",
    "    epsilon = 1e-6\n",
    "    combined_df['adjusted_scroll'] = np.where(\n",
    "        combined_df['body_length'] > epsilon,\n",
    "        combined_df['scroll_percentage'] / ((combined_df['body_length'] + epsilon) / 1000),\n",
    "        combined_df['scroll_percentage']\n",
    "    )\n",
    "\n",
    "    user_stats = combined_df.groupby('user_id').agg({\n",
    "        'adjusted_scroll': lambda x: np.percentile(x.dropna(), 25),\n",
    "        'read_time': lambda x: np.percentile(x.dropna(), 25)\n",
    "    }).rename(columns={'adjusted_scroll': 'scroll_threshold', 'read_time': 'read_threshold'})\n",
    "\n",
    "    user_stats['scroll_threshold'] = user_stats['scroll_threshold'].fillna(0.05)\n",
    "    user_stats['read_threshold'] = user_stats['read_threshold'].fillna(5)\n",
    "\n",
    "    combined_df = combined_df.merge(user_stats, on='user_id', how='left')\n",
    "\n",
    "    def infer_like(row):\n",
    "        clicked = False\n",
    "        if 'article_ids_inview' in row and 'article_ids_clicked' in row:\n",
    "            inview = eval(row['article_ids_inview']) if isinstance(row['article_ids_inview'], str) else row['article_ids_inview']\n",
    "            clicked = row['article_id'] in eval(row['article_ids_clicked']) if isinstance(row['article_ids_clicked'], str) else False\n",
    "        \n",
    "        scroll_ok = row['adjusted_scroll'] > row['scroll_threshold']\n",
    "        read_ok = row['read_time'] > row['read_threshold']\n",
    "\n",
    "        if row['is_low_text']:\n",
    "            return read_ok or clicked\n",
    "        elif row['body_length'] > 2000:\n",
    "            return read_ok and (scroll_ok or clicked)\n",
    "        else:\n",
    "            return read_ok or (scroll_ok and clicked)\n",
    "\n",
    "    combined_df['liked'] = combined_df.apply(infer_like, axis=1)\n",
    "\n",
    "    # Debug stats\n",
    "    print(f\"Total interactions: {len(combined_df)}\")\n",
    "    print(f\"Inferred likes: {combined_df['liked'].sum()}\")\n",
    "    print(f\"Users with likes: {combined_df[combined_df['liked']]['user_id'].nunique()}\")\n",
    "    print(f\"Articles with likes: {combined_df[combined_df['liked']]['article_id'].nunique()}\")\n",
    "\n",
    "    # Build User-Item Sparse Matrix\n",
    "    all_users = combined_df['user_id'].unique()\n",
    "    all_articles = combined_df['article_id'].unique()\n",
    "    n_users = len(all_users)\n",
    "    n_articles = len(all_articles)\n",
    "\n",
    "    user_to_idx = {uid: i for i, uid in enumerate(all_users)}\n",
    "    article_to_idx = {aid: j for j, aid in enumerate(all_articles)}\n",
    "\n",
    "    liked_interactions = combined_df[combined_df['liked']][['user_id', 'article_id']].drop_duplicates()\n",
    "    rows = [user_to_idx[uid] for uid in liked_interactions['user_id']]\n",
    "    cols = [article_to_idx[aid] for aid in liked_interactions['article_id']]\n",
    "    data = np.ones(len(liked_interactions), dtype=np.uint8)\n",
    "\n",
    "    user_item_matrix = csr_matrix((data, (rows, cols)), shape=(n_users, n_articles))\n",
    "\n",
    "    # Output and Save\n",
    "    print(f\"Matrix shape: {user_item_matrix.shape} (users: {n_users}, articles: {n_articles})\")\n",
    "    print(f\"Number of non-zero entries: {user_item_matrix.nnz}\")\n",
    "    print(f\"Sparsity: {user_item_matrix.nnz / (n_users * n_articles):.6f}\")\n",
    "\n",
    "    save_npz(output_file, user_item_matrix)\n",
    "\n",
    "    # Example for first user\n",
    "    user_idx = user_to_idx[all_users[0]]\n",
    "    liked_articles = user_item_matrix[user_idx].nonzero()[1]\n",
    "    print(f\"Articles liked by user {all_users[0]}: {[all_articles[idx] for idx in liked_articles]}\")\n",
    "\n",
    "    # Return matrix and mappings\n",
    "    return user_item_matrix, user_to_idx, article_to_idx\n",
    "\n",
    "# Example usage\n",
    "\n",
    "#user_item_matrix, user_to_idx, article_to_idx = create_sparse('data', 'user_item_likes_matrix_all.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Data file (by loading it first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users without a liked article: 0\n",
      "Number of articles without a like: 1997\n",
      "\n",
      "Top 10 users with most liked articles and total interactions:\n",
      "User 1214299: 1117 liked articles, 1636 total articles interacted with\n",
      "User 701722: 906 liked articles, 1327 total articles interacted with\n",
      "User 892045: 820 liked articles, 1217 total articles interacted with\n",
      "User 2082097: 809 liked articles, 1135 total articles interacted with\n",
      "User 527084: 801 liked articles, 1263 total articles interacted with\n",
      "User 26391: 786 liked articles, 1078 total articles interacted with\n",
      "User 1377404: 774 liked articles, 1192 total articles interacted with\n",
      "User 968619: 773 liked articles, 1148 total articles interacted with\n",
      "User 151570: 765 liked articles, 1083 total articles interacted with\n",
      "User 1021601: 757 liked articles, 1004 total articles interacted with\n",
      "\n",
      "10 users with smallest number of liked articles and total interactions:\n",
      "User 1163012: 1 liked articles, 1 total articles interacted with\n",
      "User 1596067: 1 liked articles, 7 total articles interacted with\n",
      "User 887932: 1 liked articles, 5 total articles interacted with\n",
      "User 1655538: 1 liked articles, 1 total articles interacted with\n",
      "User 1864737: 1 liked articles, 4 total articles interacted with\n",
      "User 1015973: 1 liked articles, 3 total articles interacted with\n",
      "User 1558532: 1 liked articles, 5 total articles interacted with\n",
      "User 1299269: 1 liked articles, 5 total articles interacted with\n",
      "User 2422150: 1 liked articles, 12 total articles interacted with\n",
      "User 1557452: 1 liked articles, 5 total articles interacted with\n",
      "\n",
      "10 random users with liked articles and total interactions:\n",
      "User 2161817: 13 liked articles, 19 total articles interacted with\n",
      "User 946227: 326 liked articles, 458 total articles interacted with\n",
      "User 314268: 114 liked articles, 185 total articles interacted with\n",
      "User 2177709: 174 liked articles, 263 total articles interacted with\n",
      "User 2211351: 166 liked articles, 252 total articles interacted with\n",
      "User 877789: 107 liked articles, 158 total articles interacted with\n",
      "User 1193849: 6 liked articles, 10 total articles interacted with\n",
      "User 2059032: 126 liked articles, 191 total articles interacted with\n",
      "User 1148866: 20 liked articles, 30 total articles interacted with\n",
      "User 1805626: 20 liked articles, 31 total articles interacted with\n",
      "\n",
      "Total users: 18827\n",
      "Total articles: 12068\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "def Sparse_exploration(npz_file_path, data_folder):\n",
    "    # Load the sparse matrix\n",
    "    loaded_matrix = load_npz(npz_file_path)\n",
    "    n_users, n_articles = loaded_matrix.shape\n",
    "\n",
    "    # 1. Number of users without a liked article\n",
    "    likes_per_user = loaded_matrix.sum(axis=1).A.ravel()  # Likes per user\n",
    "    users_without_likes = np.sum(likes_per_user == 0)\n",
    "    print(f\"Number of users without a liked article: {users_without_likes}\")\n",
    "\n",
    "    # 2. Number of articles without a like\n",
    "    likes_per_article = loaded_matrix.sum(axis=0).A.ravel()  # Likes per article\n",
    "    articles_without_likes = np.sum(likes_per_article == 0)\n",
    "    print(f\"Number of articles without a like: {articles_without_likes}\")\n",
    "\n",
    "    # Load original data to get all interactions and user mappings\n",
    "    Bhv_train = pd.read_parquet(f\"{data_folder}\\\\train\\\\behaviors.parquet\")\n",
    "    Hstr_train = pd.read_parquet(f\"{data_folder}\\\\train\\\\history.parquet\")\n",
    "    Bhv_val = pd.read_parquet(f\"{data_folder}\\\\validation\\\\behaviors.parquet\")\n",
    "    Hstr_val = pd.read_parquet(f\"{data_folder}\\\\validation\\\\history.parquet\")\n",
    "\n",
    "    # Combine all interactions (before like inference)\n",
    "    combined_df = pd.concat([\n",
    "        Bhv_train[['user_id', 'article_id']],\n",
    "        Hstr_train.explode('article_id_fixed')[['user_id', 'article_id_fixed']].rename(columns={'article_id_fixed': 'article_id'}),\n",
    "        Bhv_val[['user_id', 'article_id']],\n",
    "        Hstr_val.explode('article_id_fixed')[['user_id', 'article_id_fixed']].rename(columns={'article_id_fixed': 'article_id'})\n",
    "    ]).dropna(subset=['article_id'])\n",
    "\n",
    "    # Ensure article_id is integer\n",
    "    combined_df['article_id'] = combined_df['article_id'].astype(int)\n",
    "\n",
    "    # Get all unique users and recreate mapping\n",
    "    all_users = combined_df['user_id'].unique()\n",
    "    user_to_idx = {uid: i for i, uid in enumerate(all_users)}\n",
    "\n",
    "    # Calculate total unique articles interacted with per user\n",
    "    user_interactions = combined_df.groupby('user_id')['article_id'].nunique()\n",
    "\n",
    "    # 3. Top 10 users with most likes\n",
    "    top_10_indices = np.argsort(likes_per_user)[::-1][:10]  # Top 10 indices by likes (descending)\n",
    "    top_10_user_ids = [all_users[idx] for idx in top_10_indices]\n",
    "    top_10_likes = [likes_per_user[idx] for idx in top_10_indices]\n",
    "    top_10_total_interactions = [user_interactions.loc[uid] for uid in top_10_user_ids]\n",
    "\n",
    "    print(\"\\nTop 10 users with most liked articles and total interactions:\")\n",
    "    for user_id, like_count, total_count in zip(top_10_user_ids, top_10_likes, top_10_total_interactions):\n",
    "        print(f\"User {user_id}: {like_count} liked articles, {total_count} total articles interacted with\")\n",
    "\n",
    "    # 4. 10 users with smallest number of likes (excluding 0 if none exist)\n",
    "    # Since all users have at least 1 like, sort ascending\n",
    "    bottom_10_indices = np.argsort(likes_per_user)[:10]  # Bottom 10 indices by likes (ascending)\n",
    "    bottom_10_user_ids = [all_users[idx] for idx in bottom_10_indices]\n",
    "    bottom_10_likes = [likes_per_user[idx] for idx in bottom_10_indices]\n",
    "    bottom_10_total_interactions = [user_interactions.loc[uid] for uid in bottom_10_user_ids]\n",
    "\n",
    "    print(\"\\n10 users with smallest number of liked articles and total interactions:\")\n",
    "    for user_id, like_count, total_count in zip(bottom_10_user_ids, bottom_10_likes, bottom_10_total_interactions):\n",
    "        print(f\"User {user_id}: {like_count} liked articles, {total_count} total articles interacted with\")\n",
    "\n",
    "    # 5. 10 random users\n",
    "    random_indices = np.random.choice(n_users, 10, replace=False)  # 10 random indices\n",
    "    random_user_ids = [all_users[idx] for idx in random_indices]\n",
    "    random_likes = [likes_per_user[idx] for idx in random_indices]\n",
    "    random_total_interactions = [user_interactions.loc[uid] for uid in random_user_ids]\n",
    "\n",
    "    print(\"\\n10 random users with liked articles and total interactions:\")\n",
    "    for user_id, like_count, total_count in zip(random_user_ids, random_likes, random_total_interactions):\n",
    "        print(f\"User {user_id}: {like_count} liked articles, {total_count} total articles interacted with\")\n",
    "\n",
    "    # Verify totals\n",
    "    print(f\"\\nTotal users: {n_users}\")\n",
    "    print(f\"Total articles: {n_articles}\")\n",
    "\n",
    "# Example usage\n",
    "Sparse_exploration('user_item_likes_matrix_all.npz', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
